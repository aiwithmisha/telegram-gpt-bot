# Trigger redeploy to force Nixpacks to apply
import os
import asyncio
import nest_asyncio
nest_asyncio.apply()
import json
import openai
import subprocess
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters

print(f"ðŸ“¦ python-telegram-bot version: {telegram.__version__}")  # <--- Ð´Ð¾Ð±Ð°Ð²Ð¸Ð»Ð¸

# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ API-ÐºÐ»ÑŽÑ‡Ð¸ Ð¸Ð· Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
openai.api_key = OPENAI_API_KEY

# Ð¤Ð°Ð¹Ð» Ð´Ð»Ñ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð¿Ð°Ð¼ÑÑ‚Ð¸
MEMORY_FILE = "memory.json"

def load_memory():
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        return []

def save_memory(memory):
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(memory, f, ensure_ascii=False, indent=2)

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    memory = load_memory()
    memory.append({"role": "user", "content": user_message})

    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Ð¢Ñ‹ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº."},
                *memory
            ],
            temperature=0.5
        )
        reply = response.choices[0].message.content
        memory.append({"role": "assistant", "content": reply})
        save_memory(memory)
        await update.message.reply_text(reply)

    except Exception as e:
        error_text = f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ð¸ Ðº OpenAI: {type(e).__name__} â€” {e}"
        await update.message.reply_text(error_text)

# ðŸ‘‡ ÐÐ¾Ð²Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ñ‹Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    file = await context.bot.get_file(update.message.voice.file_id)
    ogg_path = "voice.ogg"
    mp3_path = "voice.mp3"

    await file.download_to_drive(ogg_path)

    try:
        subprocess.run(["ffmpeg", "-i", ogg_path, mp3_path], check=True)
    except subprocess.CalledProcessError:
        await update.message.reply_text("ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ð¸ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ.")
        return

    with open(mp3_path, "rb") as audio_file:
        transcript = openai.Audio.transcribe("whisper-1", audio_file)

    question = transcript["text"]
    await update.message.reply_text(f"ðŸ—£ Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð¾:\n{question}")

    messages = [{"role": "user", "content": question}]
    completion = openai.ChatCompletion.create(model="gpt-4o", messages=messages)
    answer = completion.choices[0].message["content"]
    await update.message.reply_text(answer)

    os.remove(ogg_path)
    os.remove(mp3_path)

# ðŸš€ Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ ÑÑ‚Ð°Ñ€Ñ‚Ð°
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¯ Ð³Ð¾Ñ‚Ð¾Ð² Ðº Ñ€Ð°Ð±Ð¾Ñ‚Ðµ. ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ð¼Ð½Ðµ Ñ‡Ñ‚Ð¾-Ð½Ð¸Ð±ÑƒÐ´ÑŒ.")

async def main():
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))

    print("ðŸš€ Ð‘Ð¾Ñ‚ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð¸ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ñ‡ÐµÑ€ÐµÐ· webhook...")

    PORT = int(os.environ.get("PORT", 8443))
    URL = os.environ.get("RAILWAY_STATIC_URL")

    if not URL:
        print("âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ RAILWAY_STATIC_URL Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°.")
        exit(1)

    await app.run_webhook(
    listen="0.0.0.0",
    port=PORT,
    webhook_url=f"{URL}/webhook"
)

if __name__ == "__main__":
    asyncio.get_event_loop().run_until_complete(main())
