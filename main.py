# Trigger redeploy to force Nixpacks to apply
import os
import json
import openai
import telegram
import subprocess

from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

print(f"üì¶ python-telegram-bot version: {telegram.__version__}", flush=True)

# –ó–∞–≥—Ä—É–∂–∞–µ–º API-–∫–ª—é—á–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
openai.api_key = OPENAI_API_KEY

# –§–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
MEMORY_FILE = "memory.json"

def load_memory():
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        return []

def save_memory(memory):
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(memory, f, ensure_ascii=False, indent=2)

# üöÄ –§—É–Ω–∫—Ü–∏—è —Å—Ç–∞—Ä—Ç–∞
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    print("‚úÖ –§—É–Ω–∫—Ü–∏—è start –≤—ã–∑–≤–∞–Ω–∞", flush=True)
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –Ø –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –ù–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å.")

# üí¨ –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ–±—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    print("üì• handle_message –≤—ã–∑–≤–∞–Ω", flush=True)
    user_message = update.message.text
    memory = load_memory()
    memory.append({"role": "user", "content": user_message})

    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "–¢—ã –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."},
                *memory
            ],
            temperature=0.5
        )
        reply = response.choices[0].message.content
        memory.append({"role": "assistant", "content": reply})
        save_memory(memory)
        await update.message.reply_text(reply)
    except Exception as e:
        error_text = f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç OpenAI: {type(e).__name__} ‚Äî {e}"
        print(error_text, flush=True)
        await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI.")

# üé§ –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        print("üé§ –ü–æ–ª—É—á–µ–Ω–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")

        voice = update.message.voice
        file_id = voice.file_id
        new_file = await context.bot.get_file(file_id)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ .ogg
        ogg_path = "voice.ogg"
        await new_file.download_to_drive(ogg_path)
        print("üì• –°–∫–∞—á–∞–Ω voice.ogg")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è .ogg –≤ .mp3
        mp3_path = "voice.mp3"
        subprocess.run(["ffmpeg", "-i", ogg_path, mp3_path], check=True)
        print("üéß –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ voice.mp3")

        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Whisper (–Ω–æ–≤—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å OpenAI >=1.0.0)
        with open(mp3_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
            )
        question = transcript.text
        print("üìù –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:", question)

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç GPT-4o
        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": question}],
        )
        answer = completion.choices[0].message.content
        print("ü§ñ –û—Ç–≤–µ—Ç GPT:", answer)

        await update.message.reply_text(answer)

        except Exception as e:
            print("‚ùå –û—à–∏–±–∫–∞ –≤ handle_voice():", e)
            await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.")
    
if __name__ == "__main__":
    print("üëÄ –ë–æ—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...", flush=True)

    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))

    print("‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞–µ–º polling...", flush=True)
    app.run_polling()
