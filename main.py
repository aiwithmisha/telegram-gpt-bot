# Trigger redeploy to force Nixpacks to apply
import os
import asyncio
import json
import openai
import subprocess
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters

# –ó–∞–≥—Ä—É–∂–∞–µ–º API-–∫–ª—é—á–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
openai.api_key = OPENAI_API_KEY

# –§–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
MEMORY_FILE = "memory.json"

def load_memory():
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        return []

def save_memory(memory):
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(memory, f, ensure_ascii=False, indent=2)

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    memory = load_memory()
    memory.append({"role": "user", "content": user_message})

    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "–¢—ã –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."},
                *memory
            ],
            temperature=0.5
        )
        reply = response.choices[0].message.content
        memory.append({"role": "assistant", "content": reply})
        save_memory(memory)
        await update.message.reply_text(reply)

    except Exception as e:
        error_text = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI: {type(e).__name__} ‚Äî {e}"
        await update.message.reply_text(error_text)

# üëá –ù–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    file = await context.bot.get_file(update.message.voice.file_id)
    ogg_path = "voice.ogg"
    mp3_path = "voice.mp3"

    await file.download_to_drive(ogg_path)

    try:
        subprocess.run(["ffmpeg", "-i", ogg_path, mp3_path], check=True)
    except subprocess.CalledProcessError:
        await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.")
        return

    with open(mp3_path, "rb") as audio_file:
        transcript = openai.Audio.transcribe("whisper-1", audio_file)

    question = transcript["text"]
    await update.message.reply_text(f"üó£ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:\n{question}")

    messages = [{"role": "user", "content": question}]
    completion = openai.ChatCompletion.create(model="gpt-4o", messages=messages)
    answer = completion.choices[0].message["content"]
    await update.message.reply_text(answer)

    os.remove(ogg_path)
    os.remove(mp3_path)

# üöÄ –§—É–Ω–∫—Ü–∏—è —Å—Ç–∞—Ä—Ç–∞
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –Ø –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ. –ù–∞–ø–∏—à–∏ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å.")

async def main():
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))

    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç —á–µ—Ä–µ–∑ webhook...")

    PORT = int(os.environ.get("PORT", 8443))
    URL = os.environ.get("RAILWAY_STATIC_URL")

    if not URL:
        print("‚ùå –û—à–∏–±–∫–∞: –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è RAILWAY_STATIC_URL –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        exit(1)

    await app.run_webhook(
        listen="0.0.0.0",
        port=PORT,
        webhook_url=f"{URL}/webhook",
        shutdown_loop=False  # üëà –∫–ª—é—á–µ–≤–∞—è —Å—Ç—Ä–æ–∫–∞
    )

if __name__ == "__main__":
    asyncio.run(main())
